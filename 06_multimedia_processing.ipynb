{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Notebook 6: Multimedia Processing\n",
                "\n",
                "This notebook implements:\n",
                "- YouTube video transcript extraction\n",
                "- Audio transcription using Whisper (pretrained)\n",
                "- Video summarization pipeline\n",
                "- Text-to-Speech conversion\n",
                "- Integration with news summarization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import libraries\n",
                "import json\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from pathlib import Path\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# YouTube transcript\n",
                "from youtube_transcript_api import YouTubeTranscriptApi\n",
                "from youtube_transcript_api._errors import TranscriptsDisabled, NoTranscriptFound\n",
                "\n",
                "# Whisper for audio transcription (pretrained)\n",
                "import torch\n",
                "import whisper\n",
                "\n",
                "# Text-to-Speech\n",
                "from gtts import gTTS\n",
                "\n",
                "# For summarization\n",
                "from transformers import pipeline\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Using device: {device}\")\n",
                "print(\"‚úì Libraries imported\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Paths\n",
                "BASE_DIR = Path(r'c:\\Users\\sagun\\Desktop\\news_project')\n",
                "RESULTS_DIR = BASE_DIR / 'results'\n",
                "VIDEO_DIR = RESULTS_DIR / 'video_summaries'\n",
                "AUDIO_DIR = RESULTS_DIR / 'audio_transcripts'\n",
                "TTS_DIR = RESULTS_DIR / 'tts_output'\n",
                "\n",
                "VIDEO_DIR.mkdir(parents=True, exist_ok=True)\n",
                "AUDIO_DIR.mkdir(parents=True, exist_ok=True)\n",
                "TTS_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "# Pretrained models\n",
                "WHISPER_MODEL = \"base\"  # Options: tiny, base, small, medium, large\n",
                "\n",
                "print(f\"Whisper Model: {WHISPER_MODEL}\")\n",
                "print(f\"Output directories created\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. YouTube Transcript Extraction"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_video_id(url):\n",
                "    \"\"\"\n",
                "    Extract video ID from YouTube URL\n",
                "    \"\"\"\n",
                "    if 'youtu.be/' in url:\n",
                "        return url.split('youtu.be/')[1].split('?')[0]\n",
                "    elif 'youtube.com/watch?v=' in url:\n",
                "        return url.split('v=')[1].split('&')[0]\n",
                "    else:\n",
                "        return url\n",
                "\n",
                "def get_youtube_transcript(video_url, languages=['ne', 'en']):\n",
                "    \"\"\"\n",
                "    Get transcript from YouTube video\n",
                "    \"\"\"\n",
                "    try:\n",
                "        video_id = extract_video_id(video_url)\n",
                "        \n",
                "        # Try to get transcript in specified languages\n",
                "        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
                "        \n",
                "        # Try manual transcripts first\n",
                "        try:\n",
                "            transcript = transcript_list.find_manually_created_transcript(languages)\n",
                "        except:\n",
                "            # Fall back to auto-generated\n",
                "            transcript = transcript_list.find_generated_transcript(languages)\n",
                "        \n",
                "        # Fetch the actual transcript\n",
                "        transcript_data = transcript.fetch()\n",
                "        \n",
                "        # Combine all text\n",
                "        full_text = ' '.join([entry['text'] for entry in transcript_data])\n",
                "        \n",
                "        return {\n",
                "            'success': True,\n",
                "            'text': full_text,\n",
                "            'language': transcript.language_code,\n",
                "            'is_generated': transcript.is_generated\n",
                "        }\n",
                "    \n",
                "    except TranscriptsDisabled:\n",
                "        return {'success': False, 'error': 'Transcripts are disabled for this video'}\n",
                "    except NoTranscriptFound:\n",
                "        return {'success': False, 'error': 'No transcript found in specified languages'}\n",
                "    except Exception as e:\n",
                "        return {'success': False, 'error': str(e)}\n",
                "\n",
                "# Test with example URLs (these are placeholders - replace with actual Nepali news videos)\n",
                "example_urls = [\n",
                "    \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\",  # Placeholder\n",
                "]\n",
                "\n",
                "print(\"YouTube Transcript Extraction Demo:\\n\")\n",
                "print(\"Note: Replace with actual Nepali news video URLs for real testing\")\n",
                "print(\"\\nExample function usage:\")\n",
                "print(\"result = get_youtube_transcript('YOUR_VIDEO_URL')\")\n",
                "print(\"if result['success']:\")\n",
                "print(\"    print(result['text'])\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Load Pretrained Whisper Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load pretrained Whisper model for audio transcription\n",
                "print(f\"Loading pretrained Whisper model: {WHISPER_MODEL}...\")\n",
                "print(\"This may take a few minutes on first run...\\n\")\n",
                "\n",
                "whisper_model = whisper.load_model(WHISPER_MODEL, device=device)\n",
                "\n",
                "print(\"‚úì Whisper model loaded successfully\")\n",
                "print(f\"Model: {WHISPER_MODEL}\")\n",
                "print(f\"Device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Audio Transcription Function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def transcribe_audio(audio_file_path, language='ne'):\n",
                "    \"\"\"\n",
                "    Transcribe audio file using pretrained Whisper model\n",
                "    \n",
                "    Args:\n",
                "        audio_file_path: Path to audio file (mp3, wav, etc.)\n",
                "        language: Language code (ne for Nepali, en for English)\n",
                "    \"\"\"\n",
                "    try:\n",
                "        # Transcribe\n",
                "        result = whisper_model.transcribe(\n",
                "            str(audio_file_path),\n",
                "            language=language,\n",
                "            fp16=torch.cuda.is_available()\n",
                "        )\n",
                "        \n",
                "        return {\n",
                "            'success': True,\n",
                "            'text': result['text'],\n",
                "            'language': result['language'],\n",
                "            'segments': result['segments']\n",
                "        }\n",
                "    except Exception as e:\n",
                "        return {\n",
                "            'success': False,\n",
                "            'error': str(e)\n",
                "        }\n",
                "\n",
                "print(\"Audio Transcription Function Ready\")\n",
                "print(\"\\nUsage:\")\n",
                "print(\"result = transcribe_audio('path/to/audio.mp3', language='ne')\")\n",
                "print(\"if result['success']:\")\n",
                "print(\"    print(result['text'])\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Video Summarization Pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def summarize_video(video_url, summary_length='medium'):\n",
                "    \"\"\"\n",
                "    Complete pipeline: Extract transcript ‚Üí Summarize\n",
                "    \"\"\"\n",
                "    # Step 1: Get transcript\n",
                "    print(\"Step 1: Extracting transcript...\")\n",
                "    transcript_result = get_youtube_transcript(video_url)\n",
                "    \n",
                "    if not transcript_result['success']:\n",
                "        return {\n",
                "            'success': False,\n",
                "            'error': transcript_result['error']\n",
                "        }\n",
                "    \n",
                "    transcript_text = transcript_result['text']\n",
                "    print(f\"‚úì Transcript extracted ({len(transcript_text)} characters)\")\n",
                "    \n",
                "    # Step 2: Summarize (using simple extraction for demo)\n",
                "    print(\"\\nStep 2: Generating summary...\")\n",
                "    \n",
                "    # For actual summarization, use the mBART model from Notebook 3\n",
                "    # Here we'll do a simple extraction\n",
                "    words = transcript_text.split()\n",
                "    \n",
                "    if summary_length == 'small':\n",
                "        summary = ' '.join(words[:50])\n",
                "    elif summary_length == 'large':\n",
                "        summary = ' '.join(words[:200])\n",
                "    else:  # medium\n",
                "        summary = ' '.join(words[:100])\n",
                "    \n",
                "    print(f\"‚úì Summary generated ({len(summary)} characters)\")\n",
                "    \n",
                "    return {\n",
                "        'success': True,\n",
                "        'original_transcript': transcript_text,\n",
                "        'summary': summary,\n",
                "        'language': transcript_result['language'],\n",
                "        'video_url': video_url\n",
                "    }\n",
                "\n",
                "print(\"Video Summarization Pipeline Ready\")\n",
                "print(\"\\nThis pipeline:\")\n",
                "print(\"1. Extracts transcript from YouTube video\")\n",
                "print(\"2. Generates summary in specified length\")\n",
                "print(\"3. Returns both transcript and summary\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Text-to-Speech (TTS)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def text_to_speech(text, language='ne', output_file='output.mp3'):\n",
                "    \"\"\"\n",
                "    Convert text to speech using gTTS\n",
                "    \n",
                "    Args:\n",
                "        text: Text to convert\n",
                "        language: Language code (ne for Nepali, en for English)\n",
                "        output_file: Output filename\n",
                "    \"\"\"\n",
                "    try:\n",
                "        # Create TTS object\n",
                "        tts = gTTS(text=text, lang=language, slow=False)\n",
                "        \n",
                "        # Save to file\n",
                "        output_path = TTS_DIR / output_file\n",
                "        tts.save(str(output_path))\n",
                "        \n",
                "        return {\n",
                "            'success': True,\n",
                "            'output_file': str(output_path),\n",
                "            'text_length': len(text)\n",
                "        }\n",
                "    except Exception as e:\n",
                "        return {\n",
                "            'success': False,\n",
                "            'error': str(e)\n",
                "        }\n",
                "\n",
                "# Test TTS\n",
                "print(\"Testing Text-to-Speech...\\n\")\n",
                "\n",
                "test_text_ne = \"‡§Ø‡•ã ‡§è‡§ï ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£ ‡§π‡•ã‡•§\"\n",
                "test_text_en = \"This is a test.\"\n",
                "\n",
                "# Generate Nepali TTS\n",
                "result_ne = text_to_speech(test_text_ne, language='ne', output_file='test_nepali.mp3')\n",
                "if result_ne['success']:\n",
                "    print(f\"‚úì Nepali TTS saved to: {result_ne['output_file']}\")\n",
                "\n",
                "# Generate English TTS\n",
                "result_en = text_to_speech(test_text_en, language='en', output_file='test_english.mp3')\n",
                "if result_en['success']:\n",
                "    print(f\"‚úì English TTS saved to: {result_en['output_file']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Demo: Complete Multimedia Pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load some news summaries from previous notebook\n",
                "summaries_file = RESULTS_DIR / 'summaries' / 'all_summaries.json'\n",
                "\n",
                "if summaries_file.exists():\n",
                "    with open(summaries_file, 'r', encoding='utf-8') as f:\n",
                "        summaries = json.load(f)\n",
                "    \n",
                "    # Generate TTS for a few summaries\n",
                "    print(\"Generating TTS for news summaries...\\n\")\n",
                "    \n",
                "    for i, summary_data in enumerate(summaries[:3]):\n",
                "        summary_text = summary_data.get('medium_summary', '')\n",
                "        category = summary_data.get('category', 'unknown')\n",
                "        \n",
                "        if summary_text:\n",
                "            output_file = f\"summary_{i+1}_{category}.mp3\"\n",
                "            result = text_to_speech(summary_text, language='ne', output_file=output_file)\n",
                "            \n",
                "            if result['success']:\n",
                "                print(f\"‚úì Generated TTS for {category} summary: {output_file}\")\n",
                "    \n",
                "    print(f\"\\n‚úì TTS files saved to {TTS_DIR}\")\n",
                "else:\n",
                "    print(\"No summaries found. Run Notebook 3 first to generate summaries.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Save Multimedia Processing Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save multimedia processing configuration and results\n",
                "multimedia_config = {\n",
                "    'whisper_model': WHISPER_MODEL,\n",
                "    'supported_languages': ['ne', 'en'],\n",
                "    'capabilities': {\n",
                "        'youtube_transcript_extraction': True,\n",
                "        'audio_transcription': True,\n",
                "        'video_summarization': True,\n",
                "        'text_to_speech': True\n",
                "    },\n",
                "    'output_directories': {\n",
                "        'video_summaries': str(VIDEO_DIR),\n",
                "        'audio_transcripts': str(AUDIO_DIR),\n",
                "        'tts_output': str(TTS_DIR)\n",
                "    }\n",
                "}\n",
                "\n",
                "with open(RESULTS_DIR / 'multimedia_config.json', 'w', encoding='utf-8') as f:\n",
                "    json.dump(multimedia_config, f, ensure_ascii=False, indent=2)\n",
                "\n",
                "print(f\"‚úì Configuration saved to {RESULTS_DIR / 'multimedia_config.json'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Usage Examples"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\"*80)\n",
                "print(\"MULTIMEDIA PROCESSING - USAGE EXAMPLES\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "print(\"\\n1. YouTube Video Summarization:\")\n",
                "print(\"-\" * 80)\n",
                "print(\"\"\"result = summarize_video('https://youtube.com/watch?v=VIDEO_ID')\n",
                "if result['success']:\n",
                "    print('Summary:', result['summary'])\n",
                "\"\"\")\n",
                "\n",
                "print(\"\\n2. Audio Transcription:\")\n",
                "print(\"-\" * 80)\n",
                "print(\"\"\"result = transcribe_audio('audio.mp3', language='ne')\n",
                "if result['success']:\n",
                "    print('Transcript:', result['text'])\n",
                "\"\"\")\n",
                "\n",
                "print(\"\\n3. Text-to-Speech:\")\n",
                "print(\"-\" * 80)\n",
                "print(\"\"\"result = text_to_speech('‡§∏‡§Æ‡§æ‡§ö‡§æ‡§∞ ‡§™‡§æ‡§†', language='ne', output_file='news.mp3')\n",
                "if result['success']:\n",
                "    print('Audio saved to:', result['output_file'])\n",
                "\"\"\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*80)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\"*80)\n",
                "print(\"MULTIMEDIA PROCESSING SUMMARY\")\n",
                "print(\"=\"*80)\n",
                "print(f\"\\nü§ñ Pretrained Models:\")\n",
                "print(f\"  ‚Ä¢ Whisper (Audio Transcription): {WHISPER_MODEL}\")\n",
                "print(f\"  ‚Ä¢ gTTS (Text-to-Speech): Google TTS\")\n",
                "print(f\"\\nüé• Capabilities:\")\n",
                "print(f\"  ‚Ä¢ YouTube transcript extraction\")\n",
                "print(f\"  ‚Ä¢ Audio transcription (Nepali & English)\")\n",
                "print(f\"  ‚Ä¢ Video summarization pipeline\")\n",
                "print(f\"  ‚Ä¢ Text-to-Speech conversion\")\n",
                "print(f\"\\nüìÅ Output Directories:\")\n",
                "print(f\"  ‚Ä¢ Video summaries: {VIDEO_DIR}\")\n",
                "print(f\"  ‚Ä¢ Audio transcripts: {AUDIO_DIR}\")\n",
                "print(f\"  ‚Ä¢ TTS output: {TTS_DIR}\")\n",
                "print(f\"\\nüíæ Configuration:\")\n",
                "print(f\"  ‚Ä¢ {RESULTS_DIR / 'multimedia_config.json'}\")\n",
                "print(\"\\n‚úÖ Multimedia processing setup completed successfully!\")\n",
                "print(\"=\"*80)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}