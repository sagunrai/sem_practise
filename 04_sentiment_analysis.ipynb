{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Notebook 4: Sentiment Analysis\n",
                "\n",
                "This notebook implements:\n",
                "- Using pretrained XLM-RoBERTa for sentiment analysis\n",
                "- Classifying Nepali news as Positive, Negative, or Neutral\n",
                "- Calculating sentiment scores and confidence\n",
                "- Visualizing sentiment distribution across categories"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import libraries\n",
                "import json\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from pathlib import Path\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "import torch\n",
                "from transformers import (\n",
                "    AutoTokenizer,\n",
                "    AutoModelForSequenceClassification,\n",
                "    pipeline\n",
                ")\n",
                "from tqdm import tqdm\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Using device: {device}\")\n",
                "print(\"âœ“ Libraries imported\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Paths\n",
                "BASE_DIR = Path(r'c:\\Users\\sagun\\Desktop\\news_project')\n",
                "DATA_DIR = BASE_DIR / 'data' / 'processed'\n",
                "MODEL_DIR = BASE_DIR / 'models' / 'sentiment_analyzer'\n",
                "RESULTS_DIR = BASE_DIR / 'results'\n",
                "\n",
                "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
                "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "# Pretrained sentiment model (multilingual)\n",
                "MODEL_NAME = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
                "\n",
                "print(f\"Pretrained Model: {MODEL_NAME}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load Pretrained Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load pretrained sentiment analysis model\n",
                "print(f\"Loading pretrained model: {MODEL_NAME}...\\n\")\n",
                "\n",
                "sentiment_pipeline = pipeline(\n",
                "    \"sentiment-analysis\",\n",
                "    model=MODEL_NAME,\n",
                "    tokenizer=MODEL_NAME,\n",
                "    device=0 if torch.cuda.is_available() else -1\n",
                ")\n",
                "\n",
                "print(\"âœ“ Sentiment analysis pipeline loaded\")\n",
                "\n",
                "# Test the model\n",
                "test_texts = [\n",
                "    \"à¤¯à¥‹ à¤à¤• à¤°à¤¾à¤®à¥à¤°à¥‹ à¤¸à¤®à¤¾à¤šà¤¾à¤° à¤¹à¥‹à¥¤\",  # This is good news\n",
                "    \"à¤¯à¥‹ à¤à¤• à¤¨à¤°à¤¾à¤®à¥à¤°à¥‹ à¤˜à¤Ÿà¤¨à¤¾ à¤¹à¥‹à¥¤\",  # This is a bad incident\n",
                "]\n",
                "\n",
                "print(\"\\nTesting sentiment analysis:\")\n",
                "for text in test_texts:\n",
                "    result = sentiment_pipeline(text)[0]\n",
                "    print(f\"Text: {text}\")\n",
                "    print(f\"Sentiment: {result['label']} (confidence: {result['score']:.4f})\\n\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load test data\n",
                "with open(DATA_DIR / 'test_data.json', 'r', encoding='utf-8') as f:\n",
                "    test_data = json.load(f)\n",
                "\n",
                "df = pd.DataFrame(test_data)\n",
                "print(f\"âœ“ Loaded {len(df)} articles\")\n",
                "\n",
                "# Use a sample for demonstration\n",
                "sample_size = min(100, len(df))\n",
                "sample_df = df.sample(n=sample_size, random_state=42).copy()\n",
                "print(f\"âœ“ Using {sample_size} articles for sentiment analysis\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Perform Sentiment Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def analyze_sentiment(text, max_length=512):\n",
                "    \"\"\"\n",
                "    Analyze sentiment of text using pretrained model\n",
                "    \"\"\"\n",
                "    try:\n",
                "        # Truncate text if too long\n",
                "        words = text.split()\n",
                "        if len(words) > max_length:\n",
                "            text = ' '.join(words[:max_length])\n",
                "        \n",
                "        result = sentiment_pipeline(text)[0]\n",
                "        return {\n",
                "            'sentiment': result['label'],\n",
                "            'confidence': result['score']\n",
                "        }\n",
                "    except Exception as e:\n",
                "        return {\n",
                "            'sentiment': 'Neutral',\n",
                "            'confidence': 0.0\n",
                "        }\n",
                "\n",
                "# Analyze all articles\n",
                "print(\"Analyzing sentiment for all articles...\\n\")\n",
                "\n",
                "sentiments = []\n",
                "for text in tqdm(sample_df['text'], desc=\"Sentiment Analysis\"):\n",
                "    result = analyze_sentiment(text)\n",
                "    sentiments.append(result)\n",
                "\n",
                "# Add results to dataframe\n",
                "sample_df['sentiment'] = [s['sentiment'] for s in sentiments]\n",
                "sample_df['sentiment_confidence'] = [s['confidence'] for s in sentiments]\n",
                "\n",
                "print(\"\\nâœ“ Sentiment analysis complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Analyze Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Overall sentiment distribution\n",
                "print(\"Sentiment Distribution:\\n\")\n",
                "print(sample_df['sentiment'].value_counts())\n",
                "print(f\"\\nAverage confidence: {sample_df['sentiment_confidence'].mean():.4f}\")\n",
                "\n",
                "# Sentiment by category\n",
                "print(\"\\nSentiment by Category:\\n\")\n",
                "sentiment_by_category = pd.crosstab(sample_df['category'], sample_df['sentiment'], normalize='index') * 100\n",
                "print(sentiment_by_category.round(2))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Visualizations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create visualizations\n",
                "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
                "\n",
                "# 1. Overall sentiment distribution\n",
                "sentiment_counts = sample_df['sentiment'].value_counts()\n",
                "colors = {'Positive': '#2ecc71', 'Negative': '#e74c3c', 'Neutral': '#95a5a6'}\n",
                "sentiment_colors = [colors.get(s, '#95a5a6') for s in sentiment_counts.index]\n",
                "\n",
                "axes[0, 0].pie(sentiment_counts.values, labels=sentiment_counts.index, autopct='%1.1f%%',\n",
                "               colors=sentiment_colors, startangle=90)\n",
                "axes[0, 0].set_title('Overall Sentiment Distribution', fontweight='bold', fontsize=14)\n",
                "\n",
                "# 2. Sentiment by category\n",
                "sentiment_by_cat = pd.crosstab(sample_df['category'], sample_df['sentiment'])\n",
                "sentiment_by_cat.plot(kind='bar', stacked=True, ax=axes[0, 1], \n",
                "                      color=['#e74c3c', '#95a5a6', '#2ecc71'])\n",
                "axes[0, 1].set_title('Sentiment Distribution by Category', fontweight='bold', fontsize=14)\n",
                "axes[0, 1].set_xlabel('Category')\n",
                "axes[0, 1].set_ylabel('Count')\n",
                "axes[0, 1].legend(title='Sentiment')\n",
                "axes[0, 1].tick_params(axis='x', rotation=45)\n",
                "\n",
                "# 3. Confidence distribution\n",
                "axes[1, 0].hist(sample_df['sentiment_confidence'], bins=30, color='skyblue', edgecolor='black')\n",
                "axes[1, 0].set_title('Sentiment Confidence Distribution', fontweight='bold', fontsize=14)\n",
                "axes[1, 0].set_xlabel('Confidence Score')\n",
                "axes[1, 0].set_ylabel('Frequency')\n",
                "axes[1, 0].axvline(sample_df['sentiment_confidence'].mean(), color='red', \n",
                "                   linestyle='--', label='Mean')\n",
                "axes[1, 0].legend()\n",
                "\n",
                "# 4. Average confidence by sentiment\n",
                "avg_conf = sample_df.groupby('sentiment')['sentiment_confidence'].mean().sort_values()\n",
                "axes[1, 1].barh(avg_conf.index, avg_conf.values, \n",
                "                color=[colors.get(s, '#95a5a6') for s in avg_conf.index])\n",
                "axes[1, 1].set_title('Average Confidence by Sentiment', fontweight='bold', fontsize=14)\n",
                "axes[1, 1].set_xlabel('Average Confidence')\n",
                "axes[1, 1].set_xlim(0, 1)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(RESULTS_DIR / 'sentiment_analysis.png', dpi=300, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(f\"âœ“ Visualization saved to {RESULTS_DIR / 'sentiment_analysis.png'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Save Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save sentiment scores\n",
                "sentiment_results = sample_df[['text', 'category', 'sentiment', 'sentiment_confidence']].to_dict('records')\n",
                "\n",
                "with open(RESULTS_DIR / 'sentiment_scores.json', 'w', encoding='utf-8') as f:\n",
                "    json.dump(sentiment_results, f, ensure_ascii=False, indent=2)\n",
                "\n",
                "print(f\"âœ“ Sentiment scores saved to {RESULTS_DIR / 'sentiment_scores.json'}\")\n",
                "\n",
                "# Save statistics\n",
                "stats = {\n",
                "    'total_articles': len(sample_df),\n",
                "    'sentiment_distribution': sample_df['sentiment'].value_counts().to_dict(),\n",
                "    'average_confidence': float(sample_df['sentiment_confidence'].mean()),\n",
                "    'sentiment_by_category': sentiment_by_category.to_dict()\n",
                "}\n",
                "\n",
                "with open(RESULTS_DIR / 'sentiment_statistics.json', 'w', encoding='utf-8') as f:\n",
                "    json.dump(stats, f, ensure_ascii=False, indent=2)\n",
                "\n",
                "print(f\"âœ“ Statistics saved to {RESULTS_DIR / 'sentiment_statistics.json'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Example Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Show examples for each sentiment\n",
                "print(\"=\"*80)\n",
                "print(\"EXAMPLE SENTIMENT ANALYSIS RESULTS\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "for sentiment in ['Positive', 'Negative', 'Neutral']:\n",
                "    examples = sample_df[sample_df['sentiment'] == sentiment].head(2)\n",
                "    \n",
                "    print(f\"\\n{sentiment.upper()} Examples:\")\n",
                "    print(\"-\" * 80)\n",
                "    \n",
                "    for idx, row in examples.iterrows():\n",
                "        print(f\"\\nCategory: {row['category']}\")\n",
                "        print(f\"Text: {row['text'][:200]}...\")\n",
                "        print(f\"Sentiment: {row['sentiment']} (confidence: {row['sentiment_confidence']:.4f})\")\n",
                "        print(\"-\" * 80)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\"*80)\n",
                "print(\"SENTIMENT ANALYSIS SUMMARY\")\n",
                "print(\"=\"*80)\n",
                "print(f\"\\nðŸ¤– Pretrained Model: {MODEL_NAME}\")\n",
                "print(f\"ðŸ“Š Articles Analyzed: {len(sample_df)}\")\n",
                "print(f\"\\nðŸ“ˆ Sentiment Distribution:\")\n",
                "for sentiment, count in sample_df['sentiment'].value_counts().items():\n",
                "    percentage = (count / len(sample_df)) * 100\n",
                "    print(f\"  â€¢ {sentiment}: {count} ({percentage:.1f}%)\")\n",
                "print(f\"\\nðŸŽ¯ Average Confidence: {sample_df['sentiment_confidence'].mean():.4f}\")\n",
                "print(f\"\\nðŸ’¾ Saved Files:\")\n",
                "print(f\"  â€¢ Sentiment scores: {RESULTS_DIR / 'sentiment_scores.json'}\")\n",
                "print(f\"  â€¢ Statistics: {RESULTS_DIR / 'sentiment_statistics.json'}\")\n",
                "print(f\"  â€¢ Visualization: {RESULTS_DIR / 'sentiment_analysis.png'}\")\n",
                "print(\"\\nâœ… Sentiment analysis completed successfully!\")\n",
                "print(\"=\"*80)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}